{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import mlflow\r\n",
    "import pandas as pd\r\n",
    "import mlflow.sklearn\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('IMDB.csv')\r\n",
    "df = df.sample(500)\r\n",
    "df.to_csv('data.csv', index=False)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                review sentiment\n",
       "301  This ranks way up there on my top list of wors...  negative\n",
       "653  One of the funniest, most romantic, and most m...  positive\n",
       "755  The tighter the drama, the better the film of ...  positive\n",
       "796  \"Don't Drink the Water\" is an unbelievably bad...  negative\n",
       "218  I've gotta say, I usually like horror movies t...  negative"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>This ranks way up there on my top list of wors...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>One of the funniest, most romantic, and most m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>The tighter the drama, the better the film of ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>\"Don't Drink the Water\" is an unbelievably bad...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>I've gotta say, I usually like horror movies t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# data preprocessing\r\n",
    "\r\n",
    "# Define text preprocessing functions\r\n",
    "def lemmatization(text):\r\n",
    "    \"\"\"Lemmatize the text.\"\"\"\r\n",
    "    lemmatizer = WordNetLemmatizer()\r\n",
    "    text = text.split()\r\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\r\n",
    "    return \" \".join(text)\r\n",
    "\r\n",
    "def remove_stop_words(text):\r\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\r\n",
    "    stop_words = set(stopwords.words(\"english\"))\r\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\r\n",
    "    return \" \".join(text)\r\n",
    "\r\n",
    "def removing_numbers(text):\r\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\r\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\r\n",
    "    return text\r\n",
    "\r\n",
    "def lower_case(text):\r\n",
    "    \"\"\"Convert text to lower case.\"\"\"\r\n",
    "    text = text.split()\r\n",
    "    text = [word.lower() for word in text]\r\n",
    "    return \" \".join(text)\r\n",
    "\r\n",
    "def removing_punctuations(text):\r\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\r\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\r\n",
    "    text = text.replace('؛', \"\")\r\n",
    "    text = re.sub('\\s+', ' ', text).strip()\r\n",
    "    return text\r\n",
    "\r\n",
    "def removing_urls(text):\r\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\r\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\r\n",
    "    return url_pattern.sub(r'', text)\r\n",
    "\r\n",
    "def normalize_text(df):\r\n",
    "    \"\"\"Normalize the text data.\"\"\"\r\n",
    "    try:\r\n",
    "        df['review'] = df['review'].apply(lower_case)\r\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\r\n",
    "        df['review'] = df['review'].apply(removing_numbers)\r\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\r\n",
    "        df['review'] = df['review'].apply(removing_urls)\r\n",
    "        df['review'] = df['review'].apply(lemmatization)\r\n",
    "        return df\r\n",
    "    except Exception as e:\r\n",
    "        print(f'Error during text normalization: {e}')\r\n",
    "        raise"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df = normalize_text(df)\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error during text normalization: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mstopwords\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('stopwords')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\sreed/nltk_data'\n",
      "    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n",
      "    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n",
      "    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sreed\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sreed/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sreed\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:83\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\data.py:585\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sreed/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sreed\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mnormalize_text\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lower_case)\n\u001b[1;32m---> 44\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_stop_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(removing_numbers)\n\u001b[0;32m     46\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(removing_punctuations)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mremove_stop_words\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mremove_stop_words\u001b[39m(text):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Remove stop words from the text.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     14\u001b[0m     text \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(text)\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:120\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:85\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir, zip_name))\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:80\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\data.py:585\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    584\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sep, msg, sep)\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\sreed/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\sreed\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df['sentiment'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    269\n",
       "positive    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\r\n",
    "df = df[x]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                review  sentiment\n",
       "301  this ranks way up there on my top list of wors...          0\n",
       "653  one of the funniest, most romantic, and most m...          1\n",
       "755  the tighter the drama, the better the film of ...          1\n",
       "796  \"don't drink the water\" is an unbelievably bad...          0\n",
       "218  i've gotta say, i usually like horror movies t...          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>this ranks way up there on my top list of wors...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>one of the funniest, most romantic, and most m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>the tighter the drama, the better the film of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>\"don't drink the water\" is an unbelievably bad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>i've gotta say, i usually like horror movies t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "vectorizer = CountVectorizer(max_features=100)\r\n",
    "X = vectorizer.fit_transform(df['review'])\r\n",
    "y = df['sentiment']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "267    1\n",
      "687    0\n",
      "258    1\n",
      "596    1\n",
      "605    1\n",
      "      ..\n",
      "871    0\n",
      "1      1\n",
      "704    1\n",
      "529    1\n",
      "786    0\n",
      "Name: sentiment, Length: 375, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "pip install dagshub"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting dagshub\n",
      "  Downloading dagshub-0.6.2-py3-none-any.whl (261 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (1.4.4)\n",
      "Collecting gql[requests]\n",
      "  Using cached gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (8.5.0)\n",
      "Collecting treelib>=1.6.4\n",
      "  Using cached treelib-1.8.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: boto3 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (1.16.28)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (2.9.0.post0)\n",
      "Requirement already satisfied: semver in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (2.13.0)\n",
      "Requirement already satisfied: click>=8.0.4 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (8.1.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (0.27.0)\n",
      "Requirement already satisfied: rich>=13.1.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (14.0.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (0.6.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (2.2.3)\n",
      "Collecting pathvalidate>=3.0.0\n",
      "  Using cached pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
      "Collecting dagshub-annotation-converter>=0.1.5\n",
      "  Downloading dagshub_annotation_converter-0.1.11-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: PyYAML>=5 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (6.0.2)\n",
      "Collecting dacite~=1.6.0\n",
      "  Using cached dacite-1.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: GitPython>=3.1.29 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub) (3.1.44)\n",
      "Requirement already satisfied: colorama in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from click>=8.0.4->dagshub) (0.4.6)\n",
      "Requirement already satisfied: pillow in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (2.11.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.14.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (4.7.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx>=0.23.0->dagshub) (1.0.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx>=0.23.0->dagshub) (1.3.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx>=0.23.0->dagshub) (4.9.0)\n",
      "Requirement already satisfied: idna in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx>=0.23.0->dagshub) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx>=0.23.0->dagshub) (2025.4.26)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from rich>=13.1.0->dagshub) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from rich>=13.1.0->dagshub) (3.0.0)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from treelib>=1.6.4->dagshub) (1.17.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.28 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from boto3->dagshub) (1.19.28)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from boto3->dagshub) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from boto3->dagshub) (0.10.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dataclasses-json->dagshub) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from dataclasses-json->dagshub) (3.26.1)\n",
      "Requirement already satisfied: graphql-core<3.2.7,>=3.2 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gql[requests]->dagshub) (3.2.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gql[requests]->dagshub) (1.20.0)\n",
      "Collecting backoff<3.0,>=1.11.1\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests<3,>=2.26 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gql[requests]->dagshub) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gql[requests]->dagshub) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->dagshub) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->dagshub) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->dagshub) (2025.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from botocore<1.20.0,>=1.19.28->boto3->dagshub) (1.26.20)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (23.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic>=2.0.0->dagshub-annotation-converter>=0.1.5->dagshub) (2.33.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.4.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.1.0)\n",
      "Requirement already satisfied: multidict>=4.0 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (5.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\sreed\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\n",
      "Installing collected packages: backoff, gql, treelib, pathvalidate, dagshub-annotation-converter, dacite, dagshub\n",
      "Successfully installed backoff-2.2.1 dacite-1.6.0 dagshub-0.6.2 dagshub-annotation-converter-0.1.11 gql-3.5.3 pathvalidate-3.3.1 treelib-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  WARNING: The script gql-cli.exe is installed in 'C:\\Users\\sreed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dagshub.exe is installed in 'C:\\Users\\sreed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.3.1; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\sreed\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import dagshub\r\n",
    "\r\n",
    "mlflow.set_tracking_uri('https://dagshub.com/SREEDHA96/mlops_capstone_project.mlflow')\r\n",
    "dagshub.init(repo_owner='SREEDHA96', repo_name='mlops_capstone_project', mlflow=True)\r\n",
    "\r\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\r\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-08-09 22:17:06,083 - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/SREEDHA96/mlops_capstone_project \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"SREEDHA96/mlops_capstone_project\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"SREEDHA96/mlops_capstone_project\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-08-09 22:17:06,089 - INFO - Initialized MLflow to track repo \"SREEDHA96/mlops_capstone_project\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Repository SREEDHA96/mlops_capstone_project initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository SREEDHA96/mlops_capstone_project initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-08-09 22:17:06,092 - INFO - Repository SREEDHA96/mlops_capstone_project initialized!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/0e4a9df31b834c85b5be33ef9199a619', creation_time=1754757087301, experiment_id='0', last_update_time=1754757087301, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import mlflow\r\n",
    "import logging\r\n",
    "import os\r\n",
    "import time\r\n",
    "import joblib\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
    "\r\n",
    "# Configure logging\r\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\r\n",
    "\r\n",
    "logging.info(\"Starting MLflow run...\")\r\n",
    "\r\n",
    "with mlflow.start_run():\r\n",
    "    start_time = time.time()\r\n",
    "    \r\n",
    "    try:\r\n",
    "        logging.info(\"Logging preprocessing parameters...\")\r\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\r\n",
    "        mlflow.log_param(\"num_features\", 50)\r\n",
    "        mlflow.log_param(\"test_size\", 0.25)\r\n",
    "\r\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\r\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\r\n",
    "\r\n",
    "        logging.info(\"Fitting the model...\")\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        logging.info(\"Model training complete.\")\r\n",
    "\r\n",
    "        logging.info(\"Logging model parameters...\")\r\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\r\n",
    "\r\n",
    "        logging.info(\"Making predictions...\")\r\n",
    "        y_pred = model.predict(X_test)\r\n",
    "\r\n",
    "        logging.info(\"Calculating evaluation metrics...\")\r\n",
    "        accuracy = accuracy_score(y_test, y_pred)\r\n",
    "        precision = precision_score(y_test, y_pred)\r\n",
    "        recall = recall_score(y_test, y_pred)\r\n",
    "        f1 = f1_score(y_test, y_pred)\r\n",
    "\r\n",
    "        logging.info(\"Logging evaluation metrics...\")\r\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\r\n",
    "        mlflow.log_metric(\"precision\", precision)\r\n",
    "        mlflow.log_metric(\"recall\", recall)\r\n",
    "        mlflow.log_metric(\"f1_score\", f1)\r\n",
    "\r\n",
    "        logging.info(\"Saving and logging the model...\")\r\n",
    "        # mlflow.sklearn.log_model(model, \"model\")\r\n",
    "        joblib.dump(model,\"model.pkl\")\r\n",
    "        mlflow.log_artifact(\"model.pkl\")\r\n",
    "        # Log execution time\r\n",
    "        end_time = time.time()\r\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\r\n",
    "\r\n",
    "        # Save and log the notebook\r\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\r\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\r\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\r\n",
    "        # mlflow.log_artifact(notebook_path)\r\n",
    "\r\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\r\n",
    "\r\n",
    "        # Print the results for verification\r\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\r\n",
    "        logging.info(f\"Precision: {precision}\")\r\n",
    "        logging.info(f\"Recall: {recall}\")\r\n",
    "        logging.info(f\"F1 Score: {f1}\")\r\n",
    "\r\n",
    "    except Exception as e:\r\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-08-09 22:22:23,863 - INFO - Starting MLflow run...\n",
      "2025-08-09 22:22:24,424 - INFO - Logging preprocessing parameters...\n",
      "2025-08-09 22:22:25,676 - INFO - Initializing Logistic Regression model...\n",
      "2025-08-09 22:22:25,678 - INFO - Fitting the model...\n",
      "2025-08-09 22:22:25,728 - INFO - Model training complete.\n",
      "2025-08-09 22:22:25,729 - INFO - Logging model parameters...\n",
      "2025-08-09 22:22:26,078 - INFO - Making predictions...\n",
      "2025-08-09 22:22:26,083 - INFO - Calculating evaluation metrics...\n",
      "2025-08-09 22:22:26,126 - INFO - Logging evaluation metrics...\n",
      "2025-08-09 22:22:31,103 - INFO - Saving and logging the model...\n",
      "2025-08-09 22:22:33,256 - INFO - Model training and logging completed in 8.83 seconds.\n",
      "2025-08-09 22:22:33,263 - INFO - Accuracy: 0.696\n",
      "2025-08-09 22:22:33,270 - INFO - Precision: 0.72\n",
      "2025-08-09 22:22:33,274 - INFO - Recall: 0.6\n",
      "2025-08-09 22:22:33,278 - INFO - F1 Score: 0.6545454545454545\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🏃 View run enchanting-mule-623 at: https://dagshub.com/SREEDHA96/mlops_capstone_project.mlflow/#/experiments/0/runs/2a546b1142564147b059d42ecf9b0b36\n",
      "🧪 View experiment at: https://dagshub.com/SREEDHA96/mlops_capstone_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "interpreter": {
   "hash": "01a4d33787da03cddd64afa9e53defd2da7a4facc21e435bca404861f82d5011"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}